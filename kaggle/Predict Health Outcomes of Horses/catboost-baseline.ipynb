{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Introduction\n","\n","The objective of this classification task is to predict the health outcomes of horses based on their historical medical data. There are three potential outcomes: \"lived,\" \"died,\" and \"euthanized.\" Within this notebook, we conduct exploratory data analysis (EDA), clean and preprocess the dataset, and subsequently train a pair of baseline CatBoost classification models â€” without any hyperparameter tuning. We've opted for the CatBoost model as a baseline as it typically has reasonable performance straight out of the box. Furthermore, we delve into assessing feature importance through a SHAP analysis. Eventually, we leverage these SHAP values to identify a subset of features, which we then employ to train a second baseline model. Interestingly, this second baseline model exhibits a slight improvement in performance compared to the first one, as assessed by cross-validation micro F1 scores. \n","\n","A couple of directions to improve the performance of the baselines:\n","1. Careful feature selection and feature engineering\n","2. Hyperparameter tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-02T13:14:26.776585Z","iopub.status.busy":"2023-10-02T13:14:26.776221Z","iopub.status.idle":"2023-10-02T13:14:28.839510Z","shell.execute_reply":"2023-10-02T13:14:28.838361Z","shell.execute_reply.started":"2023-10-02T13:14:26.776558Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from catboost import CatBoostClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.metrics import f1_score\n","from scipy.stats import chi2_contingency # for association between different categorical variables\n","\n","from numbers import Number \n","from pathlib import Path\n","from typing import Optional, Dict\n","\n","plt.style.use('ggplot')\n","plt.rcParams.update(**{'figure.dpi':150})"]},{"cell_type":"markdown","metadata":{},"source":["## Loading the data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:32.204656Z","iopub.status.busy":"2023-10-02T13:14:32.203863Z","iopub.status.idle":"2023-10-02T13:14:32.305616Z","shell.execute_reply":"2023-10-02T13:14:32.304379Z","shell.execute_reply.started":"2023-10-02T13:14:32.204603Z"},"trusted":true},"outputs":[],"source":["path = Path('/kaggle/input/playground-series-s3e22')\n","train = pd.read_csv(path/'train.csv',index_col=['id'])\n","test = pd.read_csv(path/'test.csv',index_col=['id'])\n","\n","del train['hospital_number']\n","del test['hospital_number']\n","\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:32.307556Z","iopub.status.busy":"2023-10-02T13:14:32.307147Z","iopub.status.idle":"2023-10-02T13:14:32.312918Z","shell.execute_reply":"2023-10-02T13:14:32.312094Z","shell.execute_reply.started":"2023-10-02T13:14:32.307528Z"},"trusted":true},"outputs":[],"source":["print(f'Number of rows in training set: {train.shape[0]}')\n","print(f'Number of rows in test set: {test.shape[0]}')"]},{"cell_type":"markdown","metadata":{},"source":["Here's a quick snapshot of the training data. From this snapshot, we can see the following\n","1. There are 26 potential feature columns. \n","2. There are several numerical features (indicated by dtypes `float64` and `int64` dtypes). None of them have missing entries.\n","3. There are several features with dtype - `object`. These are likely categorical valued, although some of them like `age` may be processed as numerical. \n","4. Among the columns with the `object` dtype, there are a few entries with missing values."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:32.449468Z","iopub.status.busy":"2023-10-02T13:14:32.448557Z","iopub.status.idle":"2023-10-02T13:14:32.471250Z","shell.execute_reply":"2023-10-02T13:14:32.470053Z","shell.execute_reply.started":"2023-10-02T13:14:32.449433Z"},"trusted":true},"outputs":[],"source":["# quick snapshot\n","train.info()"]},{"cell_type":"markdown","metadata":{},"source":["## Target\n","\n","The goal of this task to predict `outcome` - whether the horse survived or not - based on past medical conditions. There are three classes: lived, died, and euthanized. In the cell below, we show the bar plot of the counts for each class. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:32.617837Z","iopub.status.busy":"2023-10-02T13:14:32.617036Z","iopub.status.idle":"2023-10-02T13:14:32.905659Z","shell.execute_reply":"2023-10-02T13:14:32.904721Z","shell.execute_reply.started":"2023-10-02T13:14:32.617799Z"},"trusted":true},"outputs":[],"source":["train['outcome'].value_counts().plot(kind='barh')"]},{"cell_type":"markdown","metadata":{},"source":["## Lesions \n","\n","From the description in the [original dataset](https://www.kaggle.com/datasets/yasserh/horse-survival-dataset), the columns `lesion_1`, `lesion_2` and `lesion_3` encode the site, type, subtype, and specific code. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:32.908051Z","iopub.status.busy":"2023-10-02T13:14:32.907087Z","iopub.status.idle":"2023-10-02T13:14:32.915382Z","shell.execute_reply":"2023-10-02T13:14:32.914529Z","shell.execute_reply.started":"2023-10-02T13:14:32.908018Z"},"trusted":true},"outputs":[],"source":["for i in range(1,4):\n","    column = f'lesion_{i}'\n","    print(f\"Number of unique values in {column}: {train[column].nunique()}\")"]},{"cell_type":"markdown","metadata":{},"source":["It turns out almost all the entires of `lesion_2` and `lesion_3` are 0. Therefore, we will drop them in the remaining analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:32.948494Z","iopub.status.busy":"2023-10-02T13:14:32.948073Z","iopub.status.idle":"2023-10-02T13:14:32.957191Z","shell.execute_reply":"2023-10-02T13:14:32.955914Z","shell.execute_reply.started":"2023-10-02T13:14:32.948463Z"},"trusted":true},"outputs":[],"source":["for i in range(2,4):\n","    print(train[f'lesion_{i}'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:33.040637Z","iopub.status.busy":"2023-10-02T13:14:33.040277Z","iopub.status.idle":"2023-10-02T13:14:33.050428Z","shell.execute_reply":"2023-10-02T13:14:33.049476Z","shell.execute_reply.started":"2023-10-02T13:14:33.040611Z"},"trusted":true},"outputs":[],"source":["# dropping lesion_2 and lesion_3\n","train = train.drop(['lesion_2','lesion_3'],axis=1)\n","test = test.drop(['lesion_2','lesion_3'],axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["In the following, we decode the lesion sites and types\n","\n","### Lesion site\n","\n","There are 10 different lesion sites and a case where there are no lesions."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:33.198693Z","iopub.status.busy":"2023-10-02T13:14:33.197952Z","iopub.status.idle":"2023-10-02T13:14:33.542332Z","shell.execute_reply":"2023-10-02T13:14:33.541055Z","shell.execute_reply.started":"2023-10-02T13:14:33.198641Z"},"trusted":true},"outputs":[],"source":["def map_lesion_site(value:str) -> str:\n","    if value[:2] == \"11\" and len(value) == 5:\n","        return \"all_intestinal\"\n","    elif value[0] == \"1\":\n","        return \"gastric\"\n","    elif value[0] == \"2\":\n","        return \"sm_intestine\"\n","    elif value[0] == \"3\":\n","        return \"lg_colon\"\n","    elif value[0] == \"4\":\n","        return \"lg_colon_and_cecum\"\n","    elif value[0] == \"5\":\n","        return \"cecum\"\n","    elif value[0] == \"6\":\n","        return \"transverse_colon\"\n","    elif value[0] == \"7\":\n","        return \"retum_colon\"\n","    elif value[0] == \"8\":\n","        return \"uterus\"\n","    elif value[0] == \"9\":\n","        return \"bladder\"\n","    elif value[0] == \"0\":\n","        return \"none\"\n","    else:\n","        return \"ERROR\"\n","    \n","train['lesion_site'] = train['lesion_1'].astype(str).apply(map_lesion_site)\n","test['lesion_site'] = test['lesion_1'].astype(str).apply(map_lesion_site)\n","\n","fig,ax = plt.subplots(1, 1, figsize=(6,4))\n","train['lesion_site'].value_counts().plot(kind='bar', ax=ax)\n","_ = ax.tick_params(axis='x', rotation=60)\n","# to be used later\n","site_order = [text.get_text() for text in ax.get_xticklabels()]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:33.545467Z","iopub.status.busy":"2023-10-02T13:14:33.544402Z","iopub.status.idle":"2023-10-02T13:14:34.015576Z","shell.execute_reply":"2023-10-02T13:14:34.014368Z","shell.execute_reply.started":"2023-10-02T13:14:33.545421Z"},"trusted":true},"outputs":[],"source":["ax = (\n","    train\n","    .groupby('lesion_site')['outcome']\n","    .value_counts(normalize=True)\n","    .mul(100)\n","    .rename('Percentage')\n","    .unstack()\n","    .fillna(0)\n","    .loc[site_order]\n","    .iloc[::-1]\n","    .plot(kind='barh', stacked=True, figsize=(7, 5))\n",")\n","\n","_ = ax.set_ylabel('Lesion Site')\n","_ = ax.set_xlabel('Percentage')\n","_ = ax.set_title('Outcome percentage by Lesion Site')\n","\n","plt.legend(title='Outcome', labels=['died', 'euthanized', 'lived'], loc='upper left', bbox_to_anchor=(1, 1))"]},{"cell_type":"markdown","metadata":{},"source":["### Lesion type\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:34.017476Z","iopub.status.busy":"2023-10-02T13:14:34.017171Z","iopub.status.idle":"2023-10-02T13:14:34.384346Z","shell.execute_reply":"2023-10-02T13:14:34.383214Z","shell.execute_reply.started":"2023-10-02T13:14:34.017449Z"},"trusted":true},"outputs":[],"source":["def map_lesion_type(value:str) -> str:\n","    if value == '0':\n","        return \"none\"\n","    \n","    value2 = value[2] if len(value)==5 else value[1]\n","    \n","    if value2 == '1':\n","        return \"simple\"\n","    elif value2 == '2':\n","        return 'strangulation'\n","    elif value2 == '3':\n","        return 'inflammation'\n","    elif value2 == '4':\n","        return 'other'\n","    \n","    return 'ERROR'\n","\n","train['lesion_type'] = train['lesion_1'].astype(str).apply(map_lesion_type)\n","test['lesion_type'] = test['lesion_1'].astype(str).apply(map_lesion_type)\n","\n","fig,ax = plt.subplots(1, 1, figsize=(6,4))\n","train['lesion_type'].value_counts().plot(kind='bar', ax=ax)\n","_ = ax.tick_params(axis='x', rotation=60)\n","# to be used later\n","type_order = [text.get_text() for text in ax.get_xticklabels()]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:34.388293Z","iopub.status.busy":"2023-10-02T13:14:34.387804Z","iopub.status.idle":"2023-10-02T13:14:34.735836Z","shell.execute_reply":"2023-10-02T13:14:34.734586Z","shell.execute_reply.started":"2023-10-02T13:14:34.388249Z"},"trusted":true},"outputs":[],"source":["ax = (\n","    train\n","    .groupby('lesion_type')['outcome']\n","    .value_counts(normalize=True)\n","    .mul(100)\n","    .rename('Percentage')\n","    .unstack()\n","    .fillna(0)\n","    .loc[type_order]\n","    .iloc[::-1]\n","    .plot(kind='barh', stacked=True, figsize=(7, 5))\n",")\n","\n","\n","_ = ax.set_ylabel('Lesion Tyoe')\n","_ = ax.set_xlabel('Percentage')\n","_ = ax.set_title('Outcome percentage by Lesion Type')\n","\n","plt.legend(title='Outcome', labels=['died', 'euthanized', 'lived'], loc='upper left', bbox_to_anchor=(1, 1))"]},{"cell_type":"markdown","metadata":{},"source":["**TODO**: Decode the lesion subtype and code. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:34.737966Z","iopub.status.busy":"2023-10-02T13:14:34.737512Z","iopub.status.idle":"2023-10-02T13:14:34.743756Z","shell.execute_reply":"2023-10-02T13:14:34.742581Z","shell.execute_reply.started":"2023-10-02T13:14:34.737932Z"},"trusted":true},"outputs":[],"source":["# delete lesion_1\n","del train['lesion_1']\n","del test['lesion_1']"]},{"cell_type":"markdown","metadata":{},"source":["## Numerical Features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:34.746588Z","iopub.status.busy":"2023-10-02T13:14:34.745229Z","iopub.status.idle":"2023-10-02T13:14:34.757767Z","shell.execute_reply":"2023-10-02T13:14:34.756574Z","shell.execute_reply.started":"2023-10-02T13:14:34.746542Z"},"trusted":true},"outputs":[],"source":["numerical_cols= train.select_dtypes(include=['number']).columns.tolist()\n","print(f'Number of numerical columns: {len(numerical_cols)}')"]},{"cell_type":"markdown","metadata":{},"source":["We plot the histograms of the 10 numerical features in the cell below.  The features `respiratory_rate`, `total_protein`, and `abdomo_protein`  have positive skew."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:34.760315Z","iopub.status.busy":"2023-10-02T13:14:34.759735Z","iopub.status.idle":"2023-10-02T13:14:36.703472Z","shell.execute_reply":"2023-10-02T13:14:36.702101Z","shell.execute_reply.started":"2023-10-02T13:14:34.760268Z"},"trusted":true},"outputs":[],"source":["n_rows = 2\n","n_cols = 4\n","fig,axs = plt.subplots(n_rows,n_cols,figsize=(4*n_cols,3*n_rows))\n","for i in range(n_rows):\n","    for j in range(n_cols):\n","        col_index = n_cols*i+j\n","        if col_index == 7:\n","            break\n","        _ = sns.histplot(data=train,x=numerical_cols[col_index], ax=axs[i,j],bins=20)\n","        \n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{},"source":["To confirm our observations about the skew in the distributions in some of the features, we compute the skewness statistic for the remaining 8 numerical features."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:36.705674Z","iopub.status.busy":"2023-10-02T13:14:36.705287Z","iopub.status.idle":"2023-10-02T13:14:36.716342Z","shell.execute_reply":"2023-10-02T13:14:36.715223Z","shell.execute_reply.started":"2023-10-02T13:14:36.705644Z"},"trusted":true},"outputs":[],"source":["skewness = train[numerical_cols].skew()\n","skewness"]},{"cell_type":"markdown","metadata":{},"source":["For the features with skew > 1 (i.e., those that that are positively skewed), we will apply a log1p transform and drop the original column."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:36.719415Z","iopub.status.busy":"2023-10-02T13:14:36.718530Z","iopub.status.idle":"2023-10-02T13:14:36.733212Z","shell.execute_reply":"2023-10-02T13:14:36.731904Z","shell.execute_reply.started":"2023-10-02T13:14:36.719371Z"},"trusted":true},"outputs":[],"source":["new_numerical_cols = []\n","for column, skew in skewness.items():\n","    if skew > 1:\n","        new_column = f'log1p_{column}'\n","        train[new_column] = np.log1p(train[column])\n","        test[new_column] = np.log1p(test[column])\n","        \n","        del train[column]\n","        del test[column]\n","        \n","        new_numerical_cols.append(new_column)\n","        \n","    else:\n","        new_numerical_cols.append(column)"]},{"cell_type":"markdown","metadata":{},"source":["We now plot the boxplots of the features grouped by the different classes. Some observations:\n","\n","1. The horses that lived generally had a lower `pulse`  than the other groups.\n","2. Horses that were euthanized had orders of magnitude higher `total_protein` than the other two groups, although there are quite a few outliers in the other groups."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:36.736616Z","iopub.status.busy":"2023-10-02T13:14:36.736158Z","iopub.status.idle":"2023-10-02T13:14:38.344972Z","shell.execute_reply":"2023-10-02T13:14:38.342922Z","shell.execute_reply.started":"2023-10-02T13:14:36.736586Z"},"trusted":true},"outputs":[],"source":["n_rows = 2\n","n_cols = 4\n","fig,axs = plt.subplots(n_rows,n_cols,figsize=(3*n_cols,3*n_rows))\n","for i in range(n_rows):\n","    for j in range(n_cols):\n","        col_index = n_cols*i+j\n","        if col_index == 7:\n","            break\n","            \n","        _ = sns.boxplot(data=train, y=new_numerical_cols[col_index], x='outcome', ax=axs[i,j])\n","        \n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{},"source":["Here are the density plots of the features conditioned by outcome. Here are some key observations:\n","\n","1. When examining the conditional histogram for the `pulse` feature in the context of the \"lived\" outcomes, a distinct mode is evident. This suggests that the `pulse` feature can potentially serve as a predictor for the outcome of \"lived.\"\n","2. Likewise,  a distinct mode is evident for the `log1p_total_feature` conditioned on the \"died\" outcomes. However, this mode coincides with the higher density mode of the condtional distribution `log1p_total_feature` given that the outcome is \"lived\"."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-10-02T13:14:38.346866Z","iopub.status.busy":"2023-10-02T13:14:38.346475Z","iopub.status.idle":"2023-10-02T13:14:40.767611Z","shell.execute_reply":"2023-10-02T13:14:40.766076Z","shell.execute_reply.started":"2023-10-02T13:14:38.346833Z"},"trusted":true},"outputs":[],"source":["n_rows = 2\n","n_cols = 4\n","fig,axs = plt.subplots(n_rows,n_cols,figsize=(5*n_cols,3*n_rows))\n","for i in range(n_rows):\n","    for j in range(n_cols):\n","        col_index = n_cols*i+j\n","        if col_index == 7:\n","            break\n","        \n","        \n","        column = numerical_cols[col_index]\n","        _ = sns.kdeplot(\n","            data=train, x=new_numerical_cols[col_index], hue='outcome', \n","            ax=axs[i,j], common_norm=False\n","        )\n","            \n","#         if col_index > 0:\n","#             _ = axs[i,j].get_legend().remove()\n","        \n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{},"source":["Finally, we plot the correlation heatmap, where we compute the Pearson correlations. There are no red flags here."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:40.769490Z","iopub.status.busy":"2023-10-02T13:14:40.769078Z","iopub.status.idle":"2023-10-02T13:14:41.177112Z","shell.execute_reply":"2023-10-02T13:14:41.175927Z","shell.execute_reply.started":"2023-10-02T13:14:40.769455Z"},"trusted":true},"outputs":[],"source":["corr_matrix = train[new_numerical_cols].corr(method='pearson')\n","mask =np.triu(np.ones_like(corr_matrix, dtype=bool))\n","fig,ax = plt.subplots(1,1,figsize=(5,4),dpi=150)\n","_ = sns.heatmap(corr_matrix,annot=True,fmt='.2f',mask=mask,ax=ax)\n","_ = ax.set_facecolor('w')\n","_ = ax.tick_params(axis='x', rotation=75)"]},{"cell_type":"markdown","metadata":{},"source":["## Numerical feature engineering\n","\n","We create a new feature `log_pulseSq_total_protein`: \n","$$\\texttt{log_pulseSq_total_protein} = \\log\\left(\\frac{\\texttt{pulse}^2}{\\texttt{total_protein}}\\right):$$"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:41.179057Z","iopub.status.busy":"2023-10-02T13:14:41.178645Z","iopub.status.idle":"2023-10-02T13:14:41.535633Z","shell.execute_reply":"2023-10-02T13:14:41.534566Z","shell.execute_reply.started":"2023-10-02T13:14:41.179020Z"},"trusted":true},"outputs":[],"source":["train['log_pulseSq_total_protein'] = -np.log(np.expm1(train['log1p_total_protein'])) + 2*np.log(train['pulse'])\n","test['log_pulseSq_total_protein'] = -np.log(np.expm1(test['log1p_total_protein'])) + 2*np.log(test['pulse'])\n","\n","fig,ax = plt.subplots(1,1,figsize=(5, 3))\n","_ = sns.kdeplot(data=train, x='log_pulseSq_total_protein',hue='outcome', common_norm=False, ax=ax)"]},{"cell_type":"markdown","metadata":{},"source":["## Categorical features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:41.537677Z","iopub.status.busy":"2023-10-02T13:14:41.536798Z","iopub.status.idle":"2023-10-02T13:14:41.547161Z","shell.execute_reply":"2023-10-02T13:14:41.546087Z","shell.execute_reply.started":"2023-10-02T13:14:41.537641Z"},"trusted":true},"outputs":[],"source":["rem_columns = train.drop('outcome',axis=1).select_dtypes(include=['object']).columns.tolist()\n","print(f'Number of columns with dtype object: {len(rem_columns)}')"]},{"cell_type":"markdown","metadata":{},"source":["We will exlcude any column where the mode (aka most common value) occurs in more than 85% of the entries."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:41.549290Z","iopub.status.busy":"2023-10-02T13:14:41.548597Z","iopub.status.idle":"2023-10-02T13:14:41.576371Z","shell.execute_reply":"2023-10-02T13:14:41.575027Z","shell.execute_reply.started":"2023-10-02T13:14:41.549254Z"},"trusted":true},"outputs":[],"source":["def get_mode_fraction(x:pd.Series) -> float:\n","    cts = x.value_counts(sort=True, ascending=False)\n","    return cts.iloc[0]/x.shape[0]\n","\n","for i, column in enumerate(rem_columns):\n","    mode_frac = get_mode_fraction(train[column])\n","    if mode_frac > 0.85:\n","        # drop the feature if >85% of the observations \n","        # belong to the mode\n","        print(f'Dropping {column} with the mode having {mode_frac*100:.2f}% observations')\n","        \n","        del train[column]\n","        del test[column]\n","        \n","        rem_columns.pop(i)"]},{"cell_type":"markdown","metadata":{},"source":["We now run chi-squared contigency tests to test the significance of the relationships of each categorical feature with the response. It appears that all 16 features have significant relationship with `outcome`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:41.578260Z","iopub.status.busy":"2023-10-02T13:14:41.577790Z","iopub.status.idle":"2023-10-02T13:14:41.736967Z","shell.execute_reply":"2023-10-02T13:14:41.735703Z","shell.execute_reply.started":"2023-10-02T13:14:41.578216Z"},"trusted":true},"outputs":[],"source":["def contingency_test(input_col:str, significance_level:float=0.01) -> bool:\n","    stat,pval,_,_ = chi2_contingency(pd.crosstab(train[input_col], train['outcome']))\n","    \n","    return abs(stat), pval < significance_level\n","\n","chi2_tests_df = pd.DataFrame(\n","    [contingency_test(column) for column in rem_columns],\n","    index=rem_columns,\n","    columns=['abs_stat', 'is_significant']\n",").sort_values(by=['is_significant', 'abs_stat'], ascending=False)\n","\n","print(f'Number of categorical features with signficant relationship with outcome: {chi2_tests_df[\"is_significant\"].sum()}')"]},{"cell_type":"markdown","metadata":{},"source":["In the cell below, we generate a bar plots of the counts of the categories for each of these features, *except the two lesion features decoded earlier*. Within each category, we separate the counts by class. Some preliminary observations:\n","\n","1. For all the features, the class counts seem to differ between atleast two categories, suggesting some relationship.\n","2. Some of the features like `temp_of_extremities`can be encoded as ordinal integers. This can help reduce the dimensionaloity.\n","3. For a lot of features, some of the categories have very few observations. We might need to merge these categories to learn something useful. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:41.738571Z","iopub.status.busy":"2023-10-02T13:14:41.738256Z","iopub.status.idle":"2023-10-02T13:14:45.814017Z","shell.execute_reply":"2023-10-02T13:14:45.812625Z","shell.execute_reply.started":"2023-10-02T13:14:41.738546Z"},"trusted":true},"outputs":[],"source":["n_rows = 5\n","n_cols = 3\n","fig,axs = plt.subplots(n_rows,n_cols,figsize=(5*n_cols,4*n_rows))\n","for i in range(n_rows):\n","    for j in range(n_cols):\n","        column = rem_columns[n_cols*i+j]\n","        _ = sns.countplot(data=train,x=column,hue='outcome', ax=axs[i,j])\n","        _ = axs[i,j].tick_params(axis='x', rotation=30)\n","        \n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{},"source":["The `preprocess_categorical` function performs the following operations:\n","1. Replaces erroneous categories in a couple of features with pd.NA\n","2. Merges categories with very few observations onto a different category\n","3. Ordinal encodes columns that are either binary valued or have some inherent order\n","4. Converts the `dtype` of the remaining columns to `pd.Categorical`. (while this step isn't needed for catboost, it will be useful for models such as lightgbm that can natively handle categorical features). \n","\n","**TODO**: Merge categories of the `lesion_site` feature so that the model can learn something useful for categories with very few observations."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:45.815891Z","iopub.status.busy":"2023-10-02T13:14:45.815546Z","iopub.status.idle":"2023-10-02T13:14:45.869235Z","shell.execute_reply":"2023-10-02T13:14:45.868030Z","shell.execute_reply.started":"2023-10-02T13:14:45.815861Z"},"trusted":true},"outputs":[],"source":["categorical_columns = [\n","    'mucous_membrane', 'abdomen','rectal_exam_feces', \n","    'lesion_site', 'lesion_type' \n","]\n","\n","def preprocess_categorical(df:pd.DataFrame) -> None:\n","    # cleaning some of the categorical features\n","    df['peristalsis'] = df['peristalsis'].replace('distend_small',pd.NA)\n","    df['rectal_exam_feces'] = df['rectal_exam_feces'].replace('serosanguious',pd.NA)\n","    \n","    # merging some of the categories\n","    df['capillary_refill_time'] = df['capillary_refill_time'].replace('3','more_3_sec')\n","    df['pain'] = df['pain'].replace('slight','alert')\n","    df['pain'] = df['pain'].replace('moderate', 'mild_pain')\n","    \n","    # encoding some of the catgeorical level \n","    ordinal_and_binary_dict = {\n","        'surgery': ['no','yes'], \n","        'temp_of_extremities': ['cold','cool', 'normal', 'warm'], \n","        'peripheral_pulse': ['absent','reduced', 'normal','increased'], \n","        'pain':['alert', 'depressed', 'mild_pain', 'severe_pain', 'extreme_pain'],\n","        'capillary_refill_time': ['less_3_sec', 'more_3_sec'], \n","        'peristalsis': ['absent', 'hypomotile', 'normal', 'hypermotile'], \n","        'abdominal_distention': ['none', 'slight', 'moderate', 'severe'], \n","        'nasogastric_tube': ['none', 'slight', 'significant'], \n","        'nasogastric_reflux': ['none','slight','less_1_liter', 'more_1_liter'], \n","        'abdomo_appearance': ['serosanguious', 'cloudy', 'clear'], \n","        'surgical_lesion': ['no', 'yes'], \n","        'cp_data': ['no', 'yes']\n","    }\n","    \n","    for column, levels in ordinal_and_binary_dict.items():\n","        df[column] = df[column].replace({\n","            level:i for i,level in enumerate(levels)\n","        })\n","        \n","    for column in categorical_columns:\n","        # useful for other featur\n","        df[column] = df[column].astype('category')\n","        \n","\n","# modify columns in place\n","preprocess_categorical(train)\n","preprocess_categorical(test)"]},{"cell_type":"markdown","metadata":{},"source":["## Missing values\n","\n","In the quick snapshot earlier, we found that some of the features (encoded as `object`) have some values missing. In the cell below, I compute the fraction of missing values in each column. (Note: Columns with no missing values are excluded)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:45.875425Z","iopub.status.busy":"2023-10-02T13:14:45.873953Z","iopub.status.idle":"2023-10-02T13:14:45.891241Z","shell.execute_reply":"2023-10-02T13:14:45.889898Z","shell.execute_reply.started":"2023-10-02T13:14:45.875387Z"},"trusted":true},"outputs":[],"source":["def filter_greater_than(series:pd.Series,threshold:Number) -> pd.Series:\n","    '''\n","    Returns series elements greater than threshold. This funtion can be\n","    used with the .pipe methods\n","    '''\n","    return series[series>threshold]\n","\n","def get_perc_missing(df:pd.DataFrame) -> pd.Series:\n","    return (\n","        (df.isnull().sum()/df.shape[0]*100)\n","        .sort_values(ascending=False)\n","        .pipe(filter_greater_than,threshold=0)\n","        .round(3)\n","    )\n","\n","perc_missing = get_perc_missing(train)\n","perc_missing"]},{"cell_type":"markdown","metadata":{},"source":["The same columns have missing entries in the test set too, and the percentage of missing values in the test set is roughly the same. So, we will need a concrete imputation strategy."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:45.893532Z","iopub.status.busy":"2023-10-02T13:14:45.892619Z","iopub.status.idle":"2023-10-02T13:14:45.916215Z","shell.execute_reply":"2023-10-02T13:14:45.914686Z","shell.execute_reply.started":"2023-10-02T13:14:45.893495Z"},"trusted":true},"outputs":[],"source":["perc_missing_test = get_perc_missing(test)\n","assert perc_missing.shape[0] == perc_missing_test.shape[0]\n","perc_missing_test"]},{"cell_type":"markdown","metadata":{},"source":["For `abdomen` and `rectal_exam_feces`, we add a new category called `\"missing\"` for the missing entries."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:45.918635Z","iopub.status.busy":"2023-10-02T13:14:45.917836Z","iopub.status.idle":"2023-10-02T13:14:45.936657Z","shell.execute_reply":"2023-10-02T13:14:45.935361Z","shell.execute_reply.started":"2023-10-02T13:14:45.918586Z"},"trusted":true},"outputs":[],"source":["for column in ['abdomen','rectal_exam_feces']:\n","    train[column] = train[column].astype('object').fillna('missing').astype('category')\n","    test[column] = test[column].astype('object').fillna('missing').astype('category')"]},{"cell_type":"markdown","metadata":{},"source":["For the remaining columns, we impute the missing value with the mode. \n","\n","TODO: Use a more systematic imputation strategy."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:45.939043Z","iopub.status.busy":"2023-10-02T13:14:45.938368Z","iopub.status.idle":"2023-10-02T13:14:45.956223Z","shell.execute_reply":"2023-10-02T13:14:45.954526Z","shell.execute_reply.started":"2023-10-02T13:14:45.939009Z"},"trusted":true},"outputs":[],"source":["for column in perc_missing.iloc[2:].index:\n","    mode_col = train[column].mode().iloc[0]\n","    train[column] = train[column].fillna(mode_col)\n","    test[column] = test[column].fillna(mode_col)"]},{"cell_type":"markdown","metadata":{},"source":["## Catboost model\n","\n","The function `fit_model` in the cell below, trains a catboost classification model. The function also allows the specification of hyperparameters as a dictionary through the `config` argument. If `config` is not specified, default values for the hyperparameters are used."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:45.958867Z","iopub.status.busy":"2023-10-02T13:14:45.957844Z","iopub.status.idle":"2023-10-02T13:14:45.966285Z","shell.execute_reply":"2023-10-02T13:14:45.964807Z","shell.execute_reply.started":"2023-10-02T13:14:45.958803Z"},"trusted":true},"outputs":[],"source":["def fit_model(\n","    X:pd.DataFrame,\n","    y:np.ndarray,\n","    config:Optional[Dict]=None,\n","    n_jobs:int=1,\n","    verbose:int=0,\n","    random_seed:int=100,\n",") -> CatBoostClassifier:\n","    '''\n","    Train a catboost classifier\n","    '''\n","    model = CatBoostClassifier(\n","        thread_count = n_jobs,\n","        random_seed = random_seed,\n","        verbose = verbose\n","    )\n","    \n","    if config:\n","        # if config is supplied, set the model hyperparameters\n","        model.set_params(**config)\n","        \n","    cat_features = [\n","        column for column in X.columns if X[column].dtype == 'category'\n","    ]\n","        \n","    return model.fit(X, y, cat_features= cat_features)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:45.968449Z","iopub.status.busy":"2023-10-02T13:14:45.967695Z","iopub.status.idle":"2023-10-02T13:14:53.794858Z","shell.execute_reply":"2023-10-02T13:14:53.793334Z","shell.execute_reply.started":"2023-10-02T13:14:45.968414Z"},"trusted":true},"outputs":[],"source":["X = train.drop('outcome',axis=1)\n","le = LabelEncoder()\n","y = le.fit_transform(train['outcome'].values)\n","\n","model = fit_model(X, y, n_jobs=4, verbose=50, random_seed=100)\n","model.save_model('baseline.cbm',format='cbm')"]},{"cell_type":"markdown","metadata":{},"source":["### Cross-validation\n","\n","To provide a numerical measure for the baseline, we will use the f1score estimate from 4 replicates of 10-fold stratified cross-validation. We use replicated CV here since the size of the training set is small."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-02T13:14:53.796717Z","iopub.status.busy":"2023-10-02T13:14:53.796363Z"},"trusted":true},"outputs":[],"source":["import warnings\n","from tqdm import tqdm\n","def fit_and_test_fold(X, y, train_index,test_index) -> float:\n","    X_train = X.iloc[train_index,:];X_test = X.iloc[test_index,:]\n","    y_train = y[train_index]; y_test = y[test_index]\n","    \n","    # fit model on training data\n","    with warnings.catch_warnings():\n","        warnings.simplefilter(\"ignore\")\n","        model = fit_model(X_train, y_train, n_jobs=4)\n","    \n","    # generate predictions on test data\n","    test_pred = model.predict(X_test)\n","    \n","    return f1_score(y_test, test_pred, average='micro')\n","\n","\n","cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=4, random_state=1)\n","cv_f1_scores = [None]*40\n","for i, (train_index, test_index) in tqdm(enumerate(cv.split(X,y))):\n","    cv_f1_scores[i] = fit_and_test_fold(X, y, train_index, test_index)\n","\n","cv_f1 = np.mean(cv_f1_scores)\n","print(f'CV F1 for baseline model: {cv_f1:.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# CV F1 for each replicate of 10-fold CV\n","# Clearly, there is some variability across replicates\n","np.array(cv_f1_scores).reshape(-1,10).mean(-1)"]},{"cell_type":"markdown","metadata":{},"source":["### Feature importances\n","\n","\n","\n","We now compute the gain based feature importance measures from the catboost model.\n","\n","**Notes**:\n","1. Feature importance measures from tree based models can be misleading.\n","2. In catboost, the default feature importance measure is based on the total gain from splits involving the feature."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# gain based feature importances - not necessarily the most reliable\n","feat_imp = pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True)\n","feat_imp.plot(kind='barh')"]},{"cell_type":"markdown","metadata":{},"source":["## Feature importances through SHAP\n","\n","The default feature importances computed by catboost (or any tree based model) can be misleading. Here, we will use SHAP measures to check the importance of each feature.\n","\n","SHAP values represent the impact of each feature on the model's output for a specific instance. In multiclass classification, we will have a **separate** set of SHAP values for each class. These values tell us how each feature contributes to each class prediction, i.e., distinguishing the specific class from the rest."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import shap\n","\n","explainer = shap.TreeExplainer(model)\n","shap_values = explainer.shap_values(X)"]},{"cell_type":"markdown","metadata":{},"source":["In the SHAP summary plot, we plot a horizontal bar plot of the absolute SHAP value for each feature averaged across the observations.\n","Features with longer bars have a higher influence on the model's output for the specific class. Since we have 3 classes here, we will see 3 stacked bars for each feature. The features are ordered according to the cumulative length of the 3 bars. \n","\n","Let's look at the top 3 features from the plot below. \n","\n","1. `total_protein` is very important for predicting \"died\" and \"euthanized\" outcomes, but not important for predicting \"lived\" outcomes.\n","2. `lesion_type` is very important for predicting \"lived\" and \"euthanized\" outcomes,  and moderately important for predicting \"died\" outcomes.\n","3. `pain` is important for predicting \"lived\" and \"died\" outcomes, but not important for predicting \"euthanized\" outcomes."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Average of SHAP value magnitudes across the dataset\n","shap.summary_plot(\n","    shap_values, X, plot_type=\"bar\",\n","    class_names = le.classes_,\n","    plot_size = (10,6)\n",")"]},{"cell_type":"markdown","metadata":{},"source":["In the cell below, we show the SHAP values separately by class. We only show the top 10 features."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["avg_shap_class = [\n","    pd.Series(\n","        np.abs(shap_values[i]).mean(0),\n","        index = X.columns.tolist()\n","    ).sort_values(ascending=True) for i in range(3)\n","]\n","\n","fig, axs = plt.subplots(1, 3, figsize=(15,4), dpi=150)\n","for i in range(3):\n","    _ = avg_shap_class[i].iloc[-10:].plot(kind='barh', ax=axs[i])\n","    _ = axs[i].set_title(f'Class: {le.classes_[i]}')\n","    \n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{},"source":["## Model with fewer features\n","\n","We will now consider a model with the reduced number of features. The selected features occur in the set of top 8 features for atleast one of the three classes."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["reduced_features = set()\n","for i in range(3):\n","    reduced_features = reduced_features.union(\n","        set(avg_shap_class[i].iloc[-8:].index.tolist())\n","    )\n","    \n","reduced_features = list(reduced_features)\n","print(f'Number of feature selected: {len(reduced_features)}')\n","print('List of selected features:')\n","print(reduced_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=4, random_state=1)\n","cv_f1_reduced_scores = [None]*40\n","for i, (train_index, test_index) in tqdm(enumerate(cv.split(X,y))):\n","    cv_f1_reduced_scores[i] = fit_and_test_fold(X[reduced_features], y, train_index, test_index)\n","\n","cv_f1_reduced = np.mean(cv_f1_reduced_scores)\n","print(f'CV F1 for model with reduced number of features: {cv_f1_reduced:.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# CV F1 for each replicate of 10-fold CV\n","# Clearly, there is some variability across replicates\n","np.array(cv_f1_reduced_scores).reshape(-1,10).mean(-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_reduced = fit_model(X[reduced_features], y, n_jobs=4, verbose=50, random_seed=12)\n","# save models to disk\n","model_reduced.save_model('reduced_feats.cbm',format='cbm')"]},{"cell_type":"markdown","metadata":{},"source":["## Test predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission = pd.DataFrame({\n","    'id':test.index.values,\n","    'outcome':le.inverse_transform(model.predict(test).ravel())\n","})\n","submission.to_csv('submission_orig.csv',index=False)\n","submission['outcome'].value_counts()/submission.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission = pd.DataFrame({\n","    'id':test.index.values,\n","    'outcome':le.inverse_transform(model_reduced.predict(test[reduced_features]).ravel())\n","})\n","submission.to_csv('submission_reduced.csv',index=False)\n","submission['outcome'].value_counts()/submission.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
