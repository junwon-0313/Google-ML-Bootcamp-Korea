{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439e8fe8",
   "metadata": {
    "papermill": {
     "duration": 0.01246,
     "end_time": "2023-11-06T00:52:28.542127",
     "exception": false,
     "start_time": "2023-11-06T00:52:28.529667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ”¥ Binary Prediction of Smoker Status using Bio-Signals and XGBoost\n",
    "## Playground Series - Season 3, Episode 24\n",
    "**According to a World Health Organization report, the number of deaths caused by smoking will reach 10 million by 2030.**\n",
    "\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=12R-zs-F0GsztmEAGj0PDK8Nur9b_OlZw\" width=\"500px\" height=\"500px\">\n",
    "\n",
    "**Notebook Strategy & Results of Experimentation**\n",
    "* Configure the Notebook\n",
    "* Load the Datasets and the Original Dataset **(Original dataset, helps quite a lot)**\n",
    "* Explore the Information Loaded **(Data looks good nothing needed)**\n",
    "* Clean and Transform the Data **(Nothing needed)**\n",
    "* Create some Features\n",
    "     * BMI **(Feature didn't add any value)**\n",
    "     * Kmeans Features\n",
    "         * Height (cm) **(Feature didn't add any value) -- Rank top among others...**\n",
    "         * All Features **(Feature didn't add any value)**\n",
    "     * I Created multiple ratio feature, basically all of them using a loop **(None of them make an improvement)**\n",
    "     * Once I completed training the model I tried to use pseudolabeling **(model doesn't improve the CV core improve but not the LB score)**\n",
    "* Feature Standarization\n",
    "    * Robust **(Make the model worst)**\n",
    "* Machine Learning Model\n",
    "    * XGBoost Cross Validation **(I used a 5, 10 and 20 folds; The 10 is the best option so far)**\n",
    "    * XGBoost Hyper Param Optimization **(Make the model worst from my manual calibration)**\n",
    "* Model Submission\n",
    "\n",
    "\n",
    "\n",
    "**About the Dataset**\n",
    "\n",
    "Smoking has been proven to negatively affect health in a multitude of ways.Smoking has been found to harm nearly every organ of the body, cause many diseases, as well as reducing the life expectancy of smokers in general. As of 2018, smoking has been considered the leading cause of preventable morbidity and mortality in the world, continuing to plague the worldâ€™s overall health.\n",
    "\n",
    "According to a World Health Organization report, the number of deaths caused by smoking will reach 10 million by 2030.\n",
    "\n",
    "Evidence-based treatment for assistance in smoking cessation had been proposed and promoted. however, only less than one third of the participants could achieve the goal of abstinence. Many physicians found counseling for smoking cessation ineffective and time-consuming, and did not routinely do so in daily practice. To overcome this problem, several factors had been proposed to identify smokers who had a better chance of quitting, including the level of nicotine dependence, exhaled carbon monoxide (CO) concentration, cigarette amount per day, the age at smoking initiation, previous quit attempts, marital status, emotional distress, temperament and impulsivity scores, and the motivation to stop smoking. However, individual use of these factors for prediction could lead to conflicting results that were not straightforward enough for the physicians and patients to interpret and apply. Providing a prediction model might be a favorable way to understand the chance of quitting smoking for each individual smoker. Health outcome prediction models had been developed using methods of machine learning over recent years.\n",
    "\n",
    "A group of scientists are working on predictive models with smoking status as the prediction target.Your task is to help them create a machine learning model to identify the smoking status of an individual using bio-signals\n",
    "\n",
    "**Dataset Description**\n",
    "* age : 5-years gap\n",
    "* height(cm)\n",
    "* weight(kg)\n",
    "* waist(cm) : Waist circumference length\n",
    "* eyesight(left)\n",
    "* eyesight(right)\n",
    "* hearing(left)\n",
    "* hearing(right)\n",
    "* systolic : Blood pressure\n",
    "* relaxation : Blood pressure\n",
    "* fasting blood sugar\n",
    "* Cholesterol : total\n",
    "* triglyceride\n",
    "* HDL : cholesterol type\n",
    "* LDL : cholesterol type\n",
    "* hemoglobin\n",
    "* Urine protein\n",
    "* serum creatinine\n",
    "* AST : glutamic oxaloacetic transaminase type\n",
    "* ALT : glutamic oxaloacetic transaminase type\n",
    "* Gtp : Î³-GTP\n",
    "* dental caries\n",
    "* smoking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c60c9c7",
   "metadata": {
    "papermill": {
     "duration": 0.01165,
     "end_time": "2023-11-06T00:52:28.565863",
     "exception": false,
     "start_time": "2023-11-06T00:52:28.554213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook Configuration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77553fa6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:28.590845Z",
     "iopub.status.busy": "2023-11-06T00:52:28.590545Z",
     "iopub.status.idle": "2023-11-06T00:52:29.290565Z",
     "shell.execute_reply": "2023-11-06T00:52:29.289627Z"
    },
    "papermill": {
     "duration": 0.714931,
     "end_time": "2023-11-06T00:52:29.292656",
     "exception": false,
     "start_time": "2023-11-06T00:52:28.577725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5c3fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:29.318547Z",
     "iopub.status.busy": "2023-11-06T00:52:29.318124Z",
     "iopub.status.idle": "2023-11-06T00:52:34.188993Z",
     "shell.execute_reply": "2023-11-06T00:52:34.187787Z"
    },
    "papermill": {
     "duration": 4.887964,
     "end_time": "2023-11-06T00:52:34.192988",
     "exception": false,
     "start_time": "2023-11-06T00:52:29.305024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss, roc_auc_score \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc65938",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:34.221647Z",
     "iopub.status.busy": "2023-11-06T00:52:34.221303Z",
     "iopub.status.idle": "2023-11-06T00:52:34.228187Z",
     "shell.execute_reply": "2023-11-06T00:52:34.227214Z"
    },
    "papermill": {
     "duration": 0.023062,
     "end_time": "2023-11-06T00:52:34.230258",
     "exception": false,
     "start_time": "2023-11-06T00:52:34.207196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# I like to disable my Notebook Warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure notebook display settings to only use 2 decimal places, tables look nicer.\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_columns', 15) \n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "# Define some of the notebook parameters for future experiment replication.\n",
    "SEED   = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec66609",
   "metadata": {
    "papermill": {
     "duration": 0.012809,
     "end_time": "2023-11-06T00:52:34.256514",
     "exception": false,
     "start_time": "2023-11-06T00:52:34.243705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd63ff",
   "metadata": {
    "papermill": {
     "duration": 0.013083,
     "end_time": "2023-11-06T00:52:34.282619",
     "exception": false,
     "start_time": "2023-11-06T00:52:34.269536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading Datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746cdc15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:34.309861Z",
     "iopub.status.busy": "2023-11-06T00:52:34.309580Z",
     "iopub.status.idle": "2023-11-06T00:52:35.062100Z",
     "shell.execute_reply": "2023-11-06T00:52:35.061231Z"
    },
    "papermill": {
     "duration": 0.768821,
     "end_time": "2023-11-06T00:52:35.064358",
     "exception": false,
     "start_time": "2023-11-06T00:52:34.295537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a function to read the Datasets...\n",
    "def read_datasets(train_path: str, test_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Reads train and test datasets from csv files and returns them as pandas DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - train_path (str): The path to the train dataset csv file.\n",
    "    - test_path (str): The path to the test dataset csv file.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[pd.DataFrame, pd.DataFrame]: A tuple containing the train and test DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# Usage:\n",
    "train_path = './train.csv'\n",
    "test_path = './test.csv'\n",
    "train_df, test_df = read_datasets(train_path, test_path)\n",
    "\n",
    "train_df = train_df.drop(columns=['id'])\n",
    "test_df = test_df.drop(columns=['id'])\n",
    "\n",
    "train_df['is_original'] = 0\n",
    "test_df['is_original'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c5383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:35.090539Z",
     "iopub.status.busy": "2023-11-06T00:52:35.090235Z",
     "iopub.status.idle": "2023-11-06T00:52:35.225326Z",
     "shell.execute_reply": "2023-11-06T00:52:35.224535Z"
    },
    "papermill": {
     "duration": 0.150613,
     "end_time": "2023-11-06T00:52:35.227641",
     "exception": false,
     "start_time": "2023-11-06T00:52:35.077028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the current train data with the original dataset...\n",
    "original_path = './origin_train_dataset.csv'\n",
    "original_df = pd.read_csv(original_path)\n",
    "original_df['is_original'] = 1\n",
    "train_df = pd.concat([train_df, original_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb9154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:35.253645Z",
     "iopub.status.busy": "2023-11-06T00:52:35.253347Z",
     "iopub.status.idle": "2023-11-06T00:52:35.276615Z",
     "shell.execute_reply": "2023-11-06T00:52:35.275559Z"
    },
    "papermill": {
     "duration": 0.044302,
     "end_time": "2023-11-06T00:52:35.284573",
     "exception": false,
     "start_time": "2023-11-06T00:52:35.240271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70a826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:35.310852Z",
     "iopub.status.busy": "2023-11-06T00:52:35.310562Z",
     "iopub.status.idle": "2023-11-06T00:52:35.322733Z",
     "shell.execute_reply": "2023-11-06T00:52:35.321541Z"
    },
    "papermill": {
     "duration": 0.027411,
     "end_time": "2023-11-06T00:52:35.324540",
     "exception": false,
     "start_time": "2023-11-06T00:52:35.297129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce17df83",
   "metadata": {
    "papermill": {
     "duration": 0.012202,
     "end_time": "2023-11-06T00:52:35.349150",
     "exception": false,
     "start_time": "2023-11-06T00:52:35.336948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d955e",
   "metadata": {
    "papermill": {
     "duration": 0.01246,
     "end_time": "2023-11-06T00:52:35.414990",
     "exception": false,
     "start_time": "2023-11-06T00:52:35.402530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Exploring Loading Information..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d33448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:35.441759Z",
     "iopub.status.busy": "2023-11-06T00:52:35.441433Z",
     "iopub.status.idle": "2023-11-06T00:52:35.783067Z",
     "shell.execute_reply": "2023-11-06T00:52:35.782209Z"
    },
    "papermill": {
     "duration": 0.357492,
     "end_time": "2023-11-06T00:52:35.785300",
     "exception": false,
     "start_time": "2023-11-06T00:52:35.427808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def analyze_dataframe(df):\n",
    "    \"\"\"\n",
    "    Analyze a pandas DataFrame and provide a summary of its characteristics.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"DataFrame Information:\")\n",
    "    print(\"----------------------\")\n",
    "    display(df.info(verbose=True, show_counts=True))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"DataFrame Values:\")\n",
    "    print(\"----------------------\")\n",
    "    display(df.head(5).T)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Description:\")\n",
    "    print(\"----------------------\")\n",
    "    display(df.describe().T)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Null Values:\")\n",
    "    print(\"----------------------\")\n",
    "    display(df.isnull().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Duplicated Rows:\")\n",
    "    print(\"--------------------------\")\n",
    "    display(df.duplicated().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Unique Values:\")\n",
    "    print(\"------------------------\")\n",
    "    display(df.nunique())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Shape:\")\n",
    "    print(\"----------------\")\n",
    "    print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "\n",
    "# Usage\n",
    "analyze_dataframe(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344357f3",
   "metadata": {
    "papermill": {
     "duration": 0.014382,
     "end_time": "2023-11-06T00:52:35.814956",
     "exception": false,
     "start_time": "2023-11-06T00:52:35.800574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072fdb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:35.845663Z",
     "iopub.status.busy": "2023-11-06T00:52:35.845307Z",
     "iopub.status.idle": "2023-11-06T00:52:36.006972Z",
     "shell.execute_reply": "2023-11-06T00:52:36.006183Z"
    },
    "papermill": {
     "duration": 0.179956,
     "end_time": "2023-11-06T00:52:36.009359",
     "exception": false,
     "start_time": "2023-11-06T00:52:35.829403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Remove duplicate rows from a DataFrame and print the number of duplicates found and removed.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "    - df_no_duplicates: DataFrame with duplicates removed\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify duplicates\n",
    "    duplicates = df[df.duplicated()]\n",
    "\n",
    "    # Print number of duplicates found and removed\n",
    "    print(f\"Number of duplicates found and removed: {len(duplicates)}\")\n",
    "\n",
    "    # Remove duplicates\n",
    "    df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "    return df_no_duplicates\n",
    "\n",
    "train_df = remove_duplicates(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe51673",
   "metadata": {
    "papermill": {
     "duration": 0.014364,
     "end_time": "2023-11-06T00:52:36.038767",
     "exception": false,
     "start_time": "2023-11-06T00:52:36.024403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803ea00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:36.069240Z",
     "iopub.status.busy": "2023-11-06T00:52:36.068889Z",
     "iopub.status.idle": "2023-11-06T00:52:36.074063Z",
     "shell.execute_reply": "2023-11-06T00:52:36.073212Z"
    },
    "papermill": {
     "duration": 0.022603,
     "end_time": "2023-11-06T00:52:36.076017",
     "exception": false,
     "start_time": "2023-11-06T00:52:36.053414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df['BMI'] = df['weight(kg)'] / ((df['height(cm)'] / 100) ** 2)\n",
    "    df['HW_Ratio'] = df['height(cm)'] / df['waist(cm)']\n",
    "    df['HA_Ratio'] = df['height(cm)'] / df['age']\n",
    "    return df\n",
    "\n",
    "# train_df = create_features(train_df)\n",
    "# test_df = create_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a958dfb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:36.106612Z",
     "iopub.status.busy": "2023-11-06T00:52:36.105853Z",
     "iopub.status.idle": "2023-11-06T00:52:36.111929Z",
     "shell.execute_reply": "2023-11-06T00:52:36.111066Z"
    },
    "papermill": {
     "duration": 0.02346,
     "end_time": "2023-11-06T00:52:36.113960",
     "exception": false,
     "start_time": "2023-11-06T00:52:36.090500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def massive_feature(df, ignore_list):\n",
    "    features = [feat for feat in df.columns if feat not in ignore_list]\n",
    "\n",
    "    for idx1, col_one in enumerate(features):\n",
    "        for idx2, col_two in enumerate(features):\n",
    "            if idx1 < idx2:\n",
    "                df[col_one +'_to_'+ col_two] = df[col_one] / df[col_two]\n",
    "    return df\n",
    "\n",
    "# train_df = massive_feature(train_df, ignore_list = ['id', 'smoking', 'is_original', 'dental caries','hearing(left)','hearing(right)',])\n",
    "# test_df = massive_feature(test_df, ignore_list = ['id', 'smoking', 'is_original', 'dental caries','hearing(left)','hearing(right)',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50c252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:36.144420Z",
     "iopub.status.busy": "2023-11-06T00:52:36.143832Z",
     "iopub.status.idle": "2023-11-06T00:52:44.444983Z",
     "shell.execute_reply": "2023-11-06T00:52:44.444199Z"
    },
    "papermill": {
     "duration": 8.318896,
     "end_time": "2023-11-06T00:52:44.447419",
     "exception": false,
     "start_time": "2023-11-06T00:52:36.128523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_outliers(df, features):\n",
    "    # Subset the dataframe to only the specified features\n",
    "    df_subset = df[features]\n",
    "    \n",
    "    # Initialize the Isolation Forest model\n",
    "    clf = IsolationForest(contamination='auto')\n",
    "    \n",
    "    # Fit the model on the subset\n",
    "    predictions = clf.fit_predict(df_subset)\n",
    "    \n",
    "    # Create a DataFrame to store the outlier count for each row\n",
    "    outlier_count_df = pd.DataFrame({\n",
    "        'Outlier_Count': [(pred == -1) for pred in predictions]\n",
    "    })\n",
    "\n",
    "    # Sum the counts for each row to get total outlier count\n",
    "    total_outliers = outlier_count_df['Outlier_Count'].sum()\n",
    "    \n",
    "    # Attach the outlier count to the original dataframe\n",
    "    df['Outlier_Count'] = outlier_count_df\n",
    "    \n",
    "    # Return the dataframe with the added outlier count column\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'df' is your dataframe and ['feature1', 'feature2'] are the features of interest\n",
    "# df_with_outliers = count_outliers(df, ['feature1', 'feature2'])\n",
    "# print(df_with_outliers)\n",
    "\n",
    "ignore_list = ['id', 'smoking', 'is_original']\n",
    "features = [feat for feat in train_df.columns if feat not in ignore_list]\n",
    "train_df = count_outliers(train_df, features)\n",
    "test_df = count_outliers(test_df, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2007bd7",
   "metadata": {
    "papermill": {
     "duration": 0.014412,
     "end_time": "2023-11-06T00:52:44.476933",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.462521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['BMI'] = train_df['weight(kg)']/((train_df['height(cm)']*0.01)**2)\n",
    "# train_df.insert(len(train_df.columns) - 1, 'BMI', train_df['weight(kg)'] / ((train_df['height(cm)'] * 0.01) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ì´ìƒì¹˜ ì œê±°\n",
    "# train_df = train_df.drop(train_df[train_df['triglyceride'] > 700].index)\n",
    "# train_df = train_df.drop(train_df[train_df['HDL'] > 350].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28dbb18",
   "metadata": {
    "papermill": {
     "duration": 0.014213,
     "end_time": "2023-11-06T00:52:44.505735",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.491522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Selecting Model Features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228d4ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:44.536737Z",
     "iopub.status.busy": "2023-11-06T00:52:44.536024Z",
     "iopub.status.idle": "2023-11-06T00:52:44.541766Z",
     "shell.execute_reply": "2023-11-06T00:52:44.540915Z"
    },
    "papermill": {
     "duration": 0.023546,
     "end_time": "2023-11-06T00:52:44.543853",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.520307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Drop missing values target column of the dataset...\n",
    "categorical_features = ['hearing(left)', 'hearing(right)', 'Urine protein', 'dental caries']\n",
    "numerical_features = [feat for feat in train_df.columns if feat not in categorical_features and feat not in ['smoking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d8098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:44.575025Z",
     "iopub.status.busy": "2023-11-06T00:52:44.574284Z",
     "iopub.status.idle": "2023-11-06T00:52:44.579152Z",
     "shell.execute_reply": "2023-11-06T00:52:44.578299Z"
    },
    "papermill": {
     "duration": 0.022462,
     "end_time": "2023-11-06T00:52:44.581071",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.558609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(df, categorical_features):\n",
    "    \"\"\"\n",
    "    One-hot encode the specified categorical features in the given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas DataFrame): The input DataFrame.\n",
    "    - categorical_features (list of str): List of categorical feature names to be one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "    - pandas DataFrame: A DataFrame with the specified categorical features one-hot encoded.\n",
    "    \"\"\"\n",
    "    return pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "train_df = one_hot_encode(train_df, categorical_features)\n",
    "test_df = one_hot_encode(test_df, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dee4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:44.611749Z",
     "iopub.status.busy": "2023-11-06T00:52:44.611490Z",
     "iopub.status.idle": "2023-11-06T00:52:44.618058Z",
     "shell.execute_reply": "2023-11-06T00:52:44.617208Z"
    },
    "papermill": {
     "duration": 0.024047,
     "end_time": "2023-11-06T00:52:44.619922",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.595875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_features(df, features, n_clusters=3):\n",
    "    \"\"\"\n",
    "    Adds new features to the DataFrame based on K-means clustering.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame.\n",
    "    - features: List of features to use for clustering.\n",
    "    - n_clusters: Number of clusters for K-means clustering (default is 3).\n",
    "    \n",
    "    Returns:\n",
    "    - pandas DataFrame with new features based on the clustering.\n",
    "    \"\"\"\n",
    "    # Extract the relevant features for clustering\n",
    "    X = df[features]\n",
    "    \n",
    "    # Apply K-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)\n",
    "    \n",
    "    # Create a new feature for the cluster labels\n",
    "    df['cluster_label'] = kmeans.labels_\n",
    "    \n",
    "    # Add distance features for each cluster center\n",
    "    for i, center in enumerate(kmeans.cluster_centers_):\n",
    "        df[f'dist_to_center_{i}'] = ((X - center) ** 2).sum(axis=1) ** 0.5\n",
    "        \n",
    "    return df\n",
    "\n",
    "# train_df = kmeans_features(train_df, numerical_features, 2)\n",
    "# test_df = kmeans_features(test_df, numerical_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da7582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:44.650883Z",
     "iopub.status.busy": "2023-11-06T00:52:44.650586Z",
     "iopub.status.idle": "2023-11-06T00:52:44.656770Z",
     "shell.execute_reply": "2023-11-06T00:52:44.655658Z"
    },
    "papermill": {
     "duration": 0.023923,
     "end_time": "2023-11-06T00:52:44.658749",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.634826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_features = [col for col in train_df.columns if col not in ['id', \n",
    "                                                                 'smoking',\n",
    "                                                                 #'BMI',\n",
    "                                                                 #'weight(kg)', \n",
    "                                                                 #'height(cm)'\n",
    "                                                                ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d210419",
   "metadata": {
    "papermill": {
     "duration": 0.014874,
     "end_time": "2023-11-06T00:52:44.688649",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.673775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c988802",
   "metadata": {
    "papermill": {
     "duration": 0.014738,
     "end_time": "2023-11-06T00:52:44.718331",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.703593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " ## Feature Standarization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2958c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:44.750060Z",
     "iopub.status.busy": "2023-11-06T00:52:44.749394Z",
     "iopub.status.idle": "2023-11-06T00:52:44.756814Z",
     "shell.execute_reply": "2023-11-06T00:52:44.755777Z"
    },
    "papermill": {
     "duration": 0.025527,
     "end_time": "2023-11-06T00:52:44.758824",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.733297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def standardize_features(df, features, method='zscore'):\n",
    "    # Making a copy of the dataframe to avoid changing the original dataframe\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Selecting the features to be standardized\n",
    "    data_to_scale = df_copy[features]\n",
    "\n",
    "    # Choosing the standardization method\n",
    "    if method == 'zscore':\n",
    "        scaler = StandardScaler()\n",
    "    elif method == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif method == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose from 'zscore', 'minmax', or 'robust'.\")\n",
    "\n",
    "    # Applying the standardization\n",
    "    standardized_data = scaler.fit_transform(data_to_scale)\n",
    "\n",
    "    # Replacing the original feature values with the standardized values\n",
    "    df_copy[features] = standardized_data\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "# Usage\n",
    "# train_df = standardize_features(train_df, model_features, method = 'robust')\n",
    "# test_df = standardize_features(test_df, model_features, method = 'robust')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63cf50",
   "metadata": {
    "papermill": {
     "duration": 0.015056,
     "end_time": "2023-11-06T00:52:44.788967",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.773911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f67045c",
   "metadata": {
    "papermill": {
     "duration": 0.015109,
     "end_time": "2023-11-06T00:52:44.819525",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.804416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training an XGBoost Model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea7a60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:44.851490Z",
     "iopub.status.busy": "2023-11-06T00:52:44.850733Z",
     "iopub.status.idle": "2023-11-06T00:52:44.856825Z",
     "shell.execute_reply": "2023-11-06T00:52:44.856005Z"
    },
    "papermill": {
     "duration": 0.024268,
     "end_time": "2023-11-06T00:52:44.858841",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.834573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3dfbbc",
   "metadata": {
    "papermill": {
     "duration": 0.015125,
     "end_time": "2023-11-06T00:52:44.889342",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.874217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optuna Hyper-Param Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0b5c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:44.921501Z",
     "iopub.status.busy": "2023-11-06T00:52:44.921197Z",
     "iopub.status.idle": "2023-11-06T00:52:54.792748Z",
     "shell.execute_reply": "2023-11-06T00:52:54.791755Z"
    },
    "papermill": {
     "duration": 9.891059,
     "end_time": "2023-11-06T00:52:54.795814",
     "exception": false,
     "start_time": "2023-11-06T00:52:44.904755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Load the dataset and split it into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_df[model_features], train_df['smoking'], test_size=0.25, random_state=SEED)\n",
    "\n",
    "    # Define the hyperparameters to be optimized\n",
    "    param = {\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n",
    "        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.01, 1.0, step = 0.1),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0, step = 0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 12),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 256, 4096),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.5, step = 0.01),\n",
    "        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "\n",
    "    if param[\"booster\"] == \"dart\":\n",
    "        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        param[\"rate_drop\"] = trial.suggest_loguniform(\"rate_drop\", 1e-8, 1.0)\n",
    "        param[\"skip_drop\"] = trial.suggest_loguniform(\"skip_drop\", 1e-8, 1.0)\n",
    "\n",
    "    #Train the XGBoost model with the current hyperparameters\n",
    "    model = xgb.train(param, xgb.DMatrix(X_train, label = y_train),\n",
    "                      #num_boost_round=100\n",
    "                     )\n",
    "    \n",
    "    #model = xgb.XGBClassifier(**param)\n",
    "    #model.fit(X_train, y_train, eval_set = [(X_test, y_test)], verbose = 512)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(xgb.DMatrix(X_test))\n",
    "    loss = log_loss(y_test, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def optimize_xgboost_hyperparameters(num_trials=10):\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    optuna.logging.set_verbosity(optuna.logging.CRITICAL)\n",
    "    study.optimize(objective, n_trials=num_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    return best_params\n",
    "\n",
    "# Run the optimization\n",
    "\n",
    "optimal_params = optimize_xgboost_hyperparameters()\n",
    "print('.' * 25, '\\n')\n",
    "print(optimal_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc463f",
   "metadata": {
    "papermill": {
     "duration": 0.016079,
     "end_time": "2023-11-06T00:52:54.829907",
     "exception": false,
     "start_time": "2023-11-06T00:52:54.813828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d475b",
   "metadata": {
    "papermill": {
     "duration": 0.016009,
     "end_time": "2023-11-06T00:52:54.862430",
     "exception": false,
     "start_time": "2023-11-06T00:52:54.846421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XG Boost Model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28b651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:54.896686Z",
     "iopub.status.busy": "2023-11-06T00:52:54.896373Z",
     "iopub.status.idle": "2023-11-06T00:52:54.907642Z",
     "shell.execute_reply": "2023-11-06T00:52:54.906689Z"
    },
    "papermill": {
     "duration": 0.031042,
     "end_time": "2023-11-06T00:52:54.909757",
     "exception": false,
     "start_time": "2023-11-06T00:52:54.878715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# \n",
    "def fit_xgboost_with_kfold(df, features, target_variable, parameters, n_splits=10,  random_state=SEED):\n",
    "    \"\"\"\n",
    "    Fit an XGBoost Classifier to a pandas DataFrame with k-fold cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    target_variable (str): The name of the target variable column in the DataFrame.\n",
    "    n_splits (int): The number of folds in the cross-validation (default: 5).\n",
    "    random_state (int): A random seed for reproducible results (default: 42).\n",
    "\n",
    "    Returns:\n",
    "    xgboost.XGBClassifier: A trained XGBoost Classifier model.\n",
    "    \"\"\"\n",
    "    X = df.drop(columns=[target_variable])\n",
    "    y = df[target_variable]\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    " \n",
    "    model = xgb.XGBClassifier(**parameters)\n",
    "\n",
    "    fold_rocs = []\n",
    "    fold_loglosses = []\n",
    "    fold_predictions = []\n",
    "    fold = 1\n",
    "\n",
    "    for train_index, test_index in kfold.split(X[features], y):\n",
    "        print(f'Training Fold: {fold} ...')\n",
    "        X_train, X_test = X[features].iloc[train_index], X[features].iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set = [(X_test, y_test)], \n",
    "                  verbose = 512,)\n",
    "        \n",
    "        best_iteration = model.best_iteration  # ìµœì ì˜ íŠ¸ë¦¬ ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "\n",
    "        y_pred = model.predict(X_test, best_iteration)\n",
    "        y_pred_proba = model.predict_proba(X_test, best_iteration)[:,1]\n",
    "\n",
    "        \n",
    "        fold_logloss = log_loss(y_test, y_pred_proba)\n",
    "        fold_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "        fold_rocs.append(fold_roc)\n",
    "        fold_loglosses.append(fold_logloss)\n",
    "        fold += 1\n",
    "        \n",
    "        test_pred = model.predict_proba(test_df[features])[:,1]\n",
    "        fold_predictions.append(test_pred)\n",
    "        \n",
    "        print('....', '\\n')\n",
    "\n",
    "    predictions = np.mean(fold_predictions, axis=0)\n",
    "\n",
    "    print(\"Fold Accuracies:\", fold_rocs)\n",
    "    print(\"Fold Log Losses:\", fold_loglosses)\n",
    "    print(\"Mean AUC:\", sum(fold_rocs) / len(fold_rocs))\n",
    "    print(\"Mean Log Loss:\", sum(fold_loglosses) / len(fold_loglosses))\n",
    "\n",
    "    return model, predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d3c739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:52:54.943629Z",
     "iopub.status.busy": "2023-11-06T00:52:54.943311Z",
     "iopub.status.idle": "2023-11-06T00:55:12.687728Z",
     "shell.execute_reply": "2023-11-06T00:55:12.686835Z"
    },
    "papermill": {
     "duration": 137.763955,
     "end_time": "2023-11-06T00:55:12.690073",
     "exception": false,
     "start_time": "2023-11-06T00:52:54.926118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Best Model Parameters...\n",
    "params = {'n_estimators'          : 2048,\n",
    "          'max_depth'             : 9,\n",
    "          'learning_rate'         : 0.05,\n",
    "          'booster'               : 'gbtree',\n",
    "          'subsample'             : 0.75,\n",
    "          'colsample_bytree'      : 0.30,\n",
    "          'reg_lambda'            : 1.00,\n",
    "          'reg_alpha'             : 1.00,\n",
    "          'gamma'                 : 1.00,\n",
    "          'random_state'          : SEED,\n",
    "          'objective'             : 'binary:logistic',\n",
    "          'tree_method'           : 'hist',\n",
    "          'eval_metric'           : 'auc',\n",
    "          'early_stopping_rounds' : 256,\n",
    "          'n_jobs'                : -1,\n",
    "         }\n",
    "\n",
    "\n",
    "params = {'n_estimators'          : 2048,\n",
    "          'max_depth'             : 9,\n",
    "          'learning_rate'         : 0.045,\n",
    "          'booster'               : 'gbtree',\n",
    "          'subsample'             : 0.75,\n",
    "          'colsample_bytree'      : 0.30,\n",
    "          'reg_lambda'            : 1.00,\n",
    "          'reg_alpha'             : 0.80,\n",
    "          'gamma'                 : 0.80,\n",
    "          'random_state'          : SEED,\n",
    "          'objective'             : 'binary:logistic',\n",
    "          'tree_method'           : 'hist',\n",
    "          'eval_metric'           : 'auc',\n",
    "          'early_stopping_rounds' : 256,\n",
    "          'n_jobs'                : -1,\n",
    "         }\n",
    "\n",
    "# Not used at this point...\n",
    "# opt_params = {'booster': 'dart', \n",
    "#               'lambda': 3.386345811577273e-05, \n",
    "#               'alpha': 0.2293918168443115, \n",
    "#               'subsample': 0.8, \n",
    "#               'colsample_bytree': 1.0, \n",
    "#               'max_depth': 8, \n",
    "#               'n_estimators': 3393, \n",
    "#               'eta': 0.287678021761605, \n",
    "#               'gamma': 2.8800815977486452e-06, \n",
    "#               'grow_policy': 'lossguide', \n",
    "#               'sample_type': 'uniform', \n",
    "#               'normalize_type': 'forest', \n",
    "#               'rate_drop': 8.305338078638612e-06, \n",
    "#               'skip_drop': 0.000417122371690196,\n",
    "#               'objective': 'binary:logistic',\n",
    "#               'tree_method': 'gpu_hist',\n",
    "#               'eval_metric': 'auc',\n",
    "#               'early_stopping_rounds': 256,\n",
    "#               'n_jobs': -1}\n",
    "\n",
    "\n",
    "xgboost_model, xgboost_predictions = fit_xgboost_with_kfold(train_df, \n",
    "                                                            model_features, \n",
    "                                                            target_variable='smoking',\n",
    "                                                            parameters = params, \n",
    "                                                            random_state=SEED, \n",
    "                                                            n_splits = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580facbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:55:12.734715Z",
     "iopub.status.busy": "2023-11-06T00:55:12.734378Z",
     "iopub.status.idle": "2023-11-06T00:55:16.055738Z",
     "shell.execute_reply": "2023-11-06T00:55:16.054771Z"
    },
    "papermill": {
     "duration": 3.344865,
     "end_time": "2023-11-06T00:55:16.057706",
     "exception": false,
     "start_time": "2023-11-06T00:55:12.712841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pred = xgboost_model.predict_proba(train_df[model_features])[:,1]\n",
    "train_df['pred'] = train_pred\n",
    "train_df[(train_df['smoking'] == 1) & (train_df['pred'] > 0.9)][model_features].sample(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11874373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:55:16.101238Z",
     "iopub.status.busy": "2023-11-06T00:55:16.100942Z",
     "iopub.status.idle": "2023-11-06T00:55:16.500527Z",
     "shell.execute_reply": "2023-11-06T00:55:16.499386Z"
    },
    "papermill": {
     "duration": 0.42356,
     "end_time": "2023-11-06T00:55:16.502742",
     "exception": false,
     "start_time": "2023-11-06T00:55:16.079182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['smoking'] = xgboost_predictions\n",
    "submission.to_csv('./xgb_one_hot_submission.csv', index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be2c98",
   "metadata": {
    "papermill": {
     "duration": 0.021265,
     "end_time": "2023-11-06T00:55:16.546923",
     "exception": false,
     "start_time": "2023-11-06T00:55:16.525658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506dac1",
   "metadata": {
    "papermill": {
     "duration": 0.020901,
     "end_time": "2023-11-06T00:55:16.588961",
     "exception": false,
     "start_time": "2023-11-06T00:55:16.568060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGBoost + Pseudo-Labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4c9e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:55:16.633767Z",
     "iopub.status.busy": "2023-11-06T00:55:16.632829Z",
     "iopub.status.idle": "2023-11-06T00:55:16.657573Z",
     "shell.execute_reply": "2023-11-06T00:55:16.656551Z"
    },
    "papermill": {
     "duration": 0.049354,
     "end_time": "2023-11-06T00:55:16.659533",
     "exception": false,
     "start_time": "2023-11-06T00:55:16.610179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df['predictions'] = xgboost_predictions\n",
    "test_df.head()\n",
    "\n",
    "cutoff = 0.90 # Probability CutOff...\n",
    "pseudo_set_1 = test_df[test_df['predictions'] > cutoff]\n",
    "pseudo_set_1['smoking'] = 1\n",
    "pseudo_set_1.drop(columns=['predictions'], axis = 1, inplace=True)\n",
    "\n",
    "pseudo_set_2 = test_df[test_df['predictions'] < 1 - cutoff]\n",
    "pseudo_set_2['smoking'] = 0\n",
    "pseudo_set_2.drop(columns=['predictions'], axis = 1, inplace=True)\n",
    "\n",
    "pseudo_set = pd.concat([pseudo_set_1,pseudo_set_2])\n",
    "pseudo_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069ca0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:55:16.704099Z",
     "iopub.status.busy": "2023-11-06T00:55:16.703783Z",
     "iopub.status.idle": "2023-11-06T00:57:50.240032Z",
     "shell.execute_reply": "2023-11-06T00:57:50.238604Z"
    },
    "papermill": {
     "duration": 153.561245,
     "end_time": "2023-11-06T00:57:50.242743",
     "exception": false,
     "start_time": "2023-11-06T00:55:16.681498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pseudo_train_df = pd.concat([train_df, pseudo_set])\n",
    "\n",
    "params = {'n_estimators'          : 2048,\n",
    "          'max_depth'             : 9,\n",
    "          'learning_rate'         : 0.045,\n",
    "          'booster'               : 'gbtree',\n",
    "          'subsample'             : 0.75,\n",
    "          'colsample_bytree'      : 0.30,\n",
    "          'reg_lambda'            : 1.00,\n",
    "          'reg_alpha'             : 0.80,\n",
    "          'gamma'                 : 0.80,\n",
    "          'random_state'          : SEED,\n",
    "          'objective'             : 'binary:logistic',\n",
    "          'tree_method'           : 'hist',\n",
    "          'eval_metric'           : 'auc',\n",
    "          'early_stopping_rounds' : 256,\n",
    "          'n_jobs'                : -1,\n",
    "         }\n",
    "\n",
    "xgboost_model, xgboost_predictions = fit_xgboost_with_kfold(pseudo_train_df, \n",
    "                                                            model_features, \n",
    "                                                            target_variable='smoking',\n",
    "                                                            parameters = params, \n",
    "                                                            random_state=SEED, \n",
    "                                                            n_splits = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5051c1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:57:50.297342Z",
     "iopub.status.busy": "2023-11-06T00:57:50.296692Z",
     "iopub.status.idle": "2023-11-06T00:57:50.640726Z",
     "shell.execute_reply": "2023-11-06T00:57:50.639778Z"
    },
    "papermill": {
     "duration": 0.373621,
     "end_time": "2023-11-06T00:57:50.642987",
     "exception": false,
     "start_time": "2023-11-06T00:57:50.269366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['smoking'] = xgboost_predictions\n",
    "submission.to_csv('./xgb_pseudo_one_hot_submission.csv', index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ebda0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:57:50.696259Z",
     "iopub.status.busy": "2023-11-06T00:57:50.695927Z",
     "iopub.status.idle": "2023-11-06T00:57:50.700603Z",
     "shell.execute_reply": "2023-11-06T00:57:50.699745Z"
    },
    "papermill": {
     "duration": 0.03295,
     "end_time": "2023-11-06T00:57:50.702439",
     "exception": false,
     "start_time": "2023-11-06T00:57:50.669489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Scores ...\n",
    "# Mean AUC: 0.872514935089370\n",
    "# Mean AUC: 0.873211725798716\n",
    "# Mean AUC: 0.8740200234564879\n",
    "# Mean AUC: 0.8744331572784543 ... No Features Added Best ...\n",
    "# Mean AUC: 0.8746445749361194 ... Added BMI Added\n",
    "# Mean AUC: 0.8740744699588816 ... Added Kmeans\n",
    "# Mean AUC: 0.8751253867438106 ... 0.09 LR No Features Added Best ...\n",
    "# Mean AUC: 0.8755503134941037 ... 0.08 LR No Features Added Best ...\n",
    "# Mean AUC: 0.8763032176590734 ... 0.07 LR No Features Added Best ...\n",
    "# Mean AUC: 0.8769275947935501 ...\n",
    "# Mean AUC: 0.8770171911144239\n",
    "# Mean AUC: 0.8772263976643453 ...\n",
    "# Mean AUC: 0.8774334209493363 ...\n",
    "# Mean AUC: 0.8779683441289976 ....\n",
    "# Mean AUC: 0.8779683441289976 .... \n",
    "# Mean AUC: 0.8779911796335711\n",
    "# Mean AUC: 0.8780984673339569 .... Best Model... Calibrating Hyper-Params...\n",
    "# Mean AUC: 0.8784115780235494\n",
    "# Mean AUC: 0.87843085346659 ...\n",
    "# Mean AUC: 0.878512247844634 Added IsOutlier Feature...\n",
    "# Mean AUC: 0.8792021618371045 Multiple folds...\n",
    "# Mean AUC: 0.9112707017734414 Using pseudolabels..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e679f7",
   "metadata": {
    "papermill": {
     "duration": 0.025185,
     "end_time": "2023-11-06T00:57:50.753198",
     "exception": false,
     "start_time": "2023-11-06T00:57:50.728013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a924bb",
   "metadata": {
    "papermill": {
     "duration": 0.025275,
     "end_time": "2023-11-06T00:57:50.804005",
     "exception": false,
     "start_time": "2023-11-06T00:57:50.778730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Linear Classifier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ee56d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:57:50.857142Z",
     "iopub.status.busy": "2023-11-06T00:57:50.856848Z",
     "iopub.status.idle": "2023-11-06T00:57:50.863742Z",
     "shell.execute_reply": "2023-11-06T00:57:50.862890Z"
    },
    "papermill": {
     "duration": 0.035403,
     "end_time": "2023-11-06T00:57:50.865716",
     "exception": false,
     "start_time": "2023-11-06T00:57:50.830313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_linear_classifier(train_df, test_df, features):\n",
    "    \"\"\"\n",
    "    Train a linear classifier using cross-validation on the train set \n",
    "    and return the trained model and predictions on the test set.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_df: pandas DataFrame for training\n",
    "    - test_df: pandas DataFrame for testing\n",
    "    - features: list of feature columns\n",
    "    \n",
    "    Returns:\n",
    "    - model: Trained LogisticRegression model\n",
    "    - test_predictions: Predictions on the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the features and target for training\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df['smoking']\n",
    "    \n",
    "    # Initialize the linear classifier\n",
    "    model = LogisticRegression(max_iter=500)  # max_iter is increased to ensure convergence for most datasets\n",
    "    \n",
    "    # Cross-validation\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=10, scoring='roc_auc')\n",
    "    print(f'Cross-validation scores: {scores}')\n",
    "    print(f'Average cross-validation score: {scores.mean()}')\n",
    "    \n",
    "    # Retrain on the entire training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    X_test = test_df[features]\n",
    "    test_predictions = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    return model, test_predictions\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `train_data` and `test_data` are your train and test DataFrames\n",
    "# features_list = ['feature1', 'feature2', 'feature3']  # replace with your actual feature names\n",
    "\n",
    "# lr_model, lr_predictions = train_linear_classifier(train_df, test_df, model_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de869c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:57:50.918128Z",
     "iopub.status.busy": "2023-11-06T00:57:50.917851Z",
     "iopub.status.idle": "2023-11-06T00:57:50.921661Z",
     "shell.execute_reply": "2023-11-06T00:57:50.920808Z"
    },
    "papermill": {
     "duration": 0.032035,
     "end_time": "2023-11-06T00:57:50.923461",
     "exception": false,
     "start_time": "2023-11-06T00:57:50.891426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission = pd.read_csv('/kaggle/input/playground-series-s3e24/sample_submission.csv')\n",
    "# submission['smoking'] = lr_predictions\n",
    "# submission.to_csv('lr_submission.csv', index = False)\n",
    "# submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce5b53d",
   "metadata": {
    "papermill": {
     "duration": 0.025651,
     "end_time": "2023-11-06T00:57:50.974696",
     "exception": false,
     "start_time": "2023-11-06T00:57:50.949045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d1fffc",
   "metadata": {
    "papermill": {
     "duration": 0.025308,
     "end_time": "2023-11-06T00:57:51.025608",
     "exception": false,
     "start_time": "2023-11-06T00:57:51.000300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Blended Model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80598dce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:57:51.078168Z",
     "iopub.status.busy": "2023-11-06T00:57:51.077611Z",
     "iopub.status.idle": "2023-11-06T00:57:51.085125Z",
     "shell.execute_reply": "2023-11-06T00:57:51.084277Z"
    },
    "papermill": {
     "duration": 0.035769,
     "end_time": "2023-11-06T00:57:51.087027",
     "exception": false,
     "start_time": "2023-11-06T00:57:51.051258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def blended_predictions(train, test, features):\n",
    "    # Initialize the classifiers\n",
    "    classifiers = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"hist_gbm\" : HistGradientBoostingClassifier (max_iter=300, learning_rate=0.001,  max_leaf_nodes=80),\n",
    "        \"CatBoost\": CatBoostClassifier(silent=True),\n",
    "        \"LGBM\": LGBMClassifier(),\n",
    "    }\n",
    "    \n",
    "    test_preds = []\n",
    "    \n",
    "    for name, clf in classifiers.items():\n",
    "        # Cross-validation predictions on training set\n",
    "        cross_val_pred = cross_val_predict(clf, train[features], train['smoking'], cv=10, method='predict_proba')[:, 1]\n",
    "        \n",
    "        # Fit the classifier to the entire training set\n",
    "        clf.fit(train[features], train['smoking'])\n",
    "        \n",
    "        # Predict on the test set\n",
    "        test_pred = clf.predict_proba(test[features])[:, 1]\n",
    "        test_preds.append(test_pred)\n",
    "        \n",
    "        print(f\"{name} done!\")\n",
    "    \n",
    "    # Average the predictions from all classifiers\n",
    "    blended_pred = np.mean(test_preds, axis=0)\n",
    "    \n",
    "    return blended_pred\n",
    "\n",
    "# Example usage\n",
    "# Assuming train and test dataframes already loaded with a 'target' column in the train dataset\n",
    "# features = [\"feature1\", \"feature2\", \"feature3\"]\n",
    "\n",
    "blend_predictions = blended_predictions(train_df, test_df, model_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a68c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:57:51.139789Z",
     "iopub.status.busy": "2023-11-06T00:57:51.139014Z",
     "iopub.status.idle": "2023-11-06T00:57:51.142726Z",
     "shell.execute_reply": "2023-11-06T00:57:51.142038Z"
    },
    "papermill": {
     "duration": 0.03185,
     "end_time": "2023-11-06T00:57:51.144484",
     "exception": false,
     "start_time": "2023-11-06T00:57:51.112634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['smoking'] = blend_predictions\n",
    "submission.to_csv('./blend_submission.csv', index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb02c9",
   "metadata": {
    "papermill": {
     "duration": 0.02537,
     "end_time": "2023-11-06T00:57:51.195623",
     "exception": false,
     "start_time": "2023-11-06T00:57:51.170253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf46874",
   "metadata": {
    "papermill": {
     "duration": 0.025311,
     "end_time": "2023-11-06T00:57:51.246615",
     "exception": false,
     "start_time": "2023-11-06T00:57:51.221304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Machine Learning Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a074a8d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T00:57:51.300655Z",
     "iopub.status.busy": "2023-11-06T00:57:51.300028Z",
     "iopub.status.idle": "2023-11-06T00:57:51.720110Z",
     "shell.execute_reply": "2023-11-06T00:57:51.719202Z"
    },
    "papermill": {
     "duration": 0.450454,
     "end_time": "2023-11-06T00:57:51.722818",
     "exception": false,
     "start_time": "2023-11-06T00:57:51.272364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Creates a plot to visualize the most important features...\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(train_df[model_features].columns, xgboost_model.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "importances.sort_values(by='Gini-importance', ascending=False).plot(kind='bar', rot=90, figsize=(10,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c8898d",
   "metadata": {
    "papermill": {
     "duration": 0.026526,
     "end_time": "2023-11-06T00:57:51.776805",
     "exception": false,
     "start_time": "2023-11-06T00:57:51.750279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 327.73311,
   "end_time": "2023-11-06T00:57:52.924629",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-06T00:52:25.191519",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
